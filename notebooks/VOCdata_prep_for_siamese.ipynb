{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pprint import pprint \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "# num_classes = 100\n",
    "# colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(num_classes)]\n",
    "\n",
    "VOC_CLASSES = [\n",
    "    \"background\",\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"diningtable\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"potted plant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tv/monitor\",\n",
    "]\n",
    "\n",
    "\n",
    "VOC_COLORMAP = [\n",
    "    [0, 0, 0],\n",
    "    [128, 0, 0],\n",
    "    [0, 128, 0],\n",
    "    [128, 128, 0],\n",
    "    [0, 0, 128],\n",
    "    [128, 0, 128],\n",
    "    [0, 128, 128],\n",
    "    [128, 128, 128],\n",
    "    [64, 0, 0],\n",
    "    [192, 0, 0],\n",
    "    [64, 128, 0],\n",
    "    [192, 128, 0],\n",
    "    [64, 0, 128],\n",
    "    [192, 0, 128],\n",
    "    [64, 128, 128],\n",
    "    [192, 128, 128],\n",
    "    [0, 64, 0],\n",
    "    [128, 64, 0],\n",
    "    [0, 192, 0],\n",
    "    [128, 192, 0],\n",
    "    [0, 64, 128],\n",
    "]\n",
    "\n",
    "def transparent_overlays(image, annotation, alpha=0.5):\n",
    "    img1 = image.copy()\n",
    "    img2 = annotation.copy()\n",
    "\n",
    "    # I want to put logo on top-left corner, So I create a ROI\n",
    "    rows,cols,channels = img2.shape\n",
    "    roi = img1[0:rows, 0:cols ]\n",
    "\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    # img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "    # Take only region of logo from logo image.\n",
    "    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    # dst = cv2.add(img1_bg, img2_fg)\n",
    "    dst = cv2.addWeighted(image.copy(), 1-alpha, img2_fg, alpha, 0)\n",
    "    img1[0:rows, 0:cols ] = dst\n",
    "    return dst\n",
    "\n",
    "\n",
    "num_classes = len(VOC_CLASSES)\n",
    "colors = VOC_COLORMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/voc_train_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all pairs (using the actual labels not clustering or sequencing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersectionAndUnion(imPred, imLab, numClass):\n",
    "    imPred = np.asarray(imPred).copy()\n",
    "    imLab = np.asarray(imLab).copy()\n",
    "    imPred += 1\n",
    "    imLab += 1\n",
    "    # Remove classes from unlabeled pixels in gt image.\n",
    "    # We should not penalize detections in unlabeled portions of the image.\n",
    "    imPred = imPred * (imLab > 0)\n",
    "    # Compute area intersection:\n",
    "    intersection = imPred * (imPred == imLab)\n",
    "    (area_intersection, _) = np.histogram(\n",
    "        intersection, bins=numClass, range=(1, numClass))\n",
    "    # Compute area union:\n",
    "    (area_pred, _) = np.histogram(imPred, bins=numClass, range=(1, numClass))\n",
    "    (area_lab, _) = np.histogram(imLab, bins=numClass, range=(1, numClass))\n",
    "    area_union = area_pred + area_lab - area_intersection\n",
    "    return (area_intersection, area_union)\n",
    "\n",
    "def intersectionOverUnion(IU):\n",
    "    # IoU = IU[0].sum() / IU[1].sum() # this is not good because the BG class is dominant\n",
    "    classes_in_img = np.where(IU[1] != 0) # index of the classes that have pixels in the union value\n",
    "    print(f\"classes_in_img are {classes_in_img}\\n\\n\")\n",
    "    print(f\"IoU is {IU[0][classes_in_img]/IU[1][classes_in_img]}\\n\\n\")\n",
    "    meanIoU = np.mean(IU[0][classes_in_img]/IU[1][classes_in_img])\n",
    "    return meanIoU\n",
    "\n",
    "def accuracy(preds, label):\n",
    "    valid = (label >= 0)\n",
    "    acc_sum = (valid * (preds == label)).sum()\n",
    "    valid_sum = valid.sum()\n",
    "    acc = float(acc_sum) / (valid_sum + 1e-10)\n",
    "    return acc, valid_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_im(img, colors):\n",
    "    for i in range(len(colors)):\n",
    "        img[:,:,0][np.where(img[:,:,0] == i)] = colors[i][0]\n",
    "        img[:,:,1][np.where(img[:,:,1] == i)] = colors[i][1]\n",
    "        img[:,:,2][np.where(img[:,:,2] == i)] = colors[i][2]\n",
    "    return img\n",
    "\n",
    "def vis_pair(img1, img2, label1, label2):\n",
    "    img1 = cv2.imread(img1)\n",
    "    img2 = cv2.imread(img2)\n",
    "    label1 = cv2.imread(label1)\n",
    "    #print(\"uniq labels in l1; {}\\n\".format({i:VOC_CLASSES[i] for i in np.unique(label1)}))\n",
    "\n",
    "    label2 = cv2.imread(label2)\n",
    "    #print(\"uniq labels in l2; {}\\n\".format({i:VOC_CLASSES[i] for i in np.unique(label2)}))\n",
    "    \n",
    "    tmp_label2 = cv2.resize(label2, (int(label1.shape[1]), int(label1.shape[0])))\n",
    "    \n",
    "    label1[np.where(label1 == 0)] = 255 # to exclude the bg from intersection\n",
    "    intersection = np.where(label1[:,:,0] == tmp_label2[:,:,0])[0].shape[0]\n",
    "    #print(np.where(tmp_label2[:,:,0] != 0 )[0].shape)\n",
    "    union = np.where(label1[:,:,0] != 255 )[0].shape[0] + np.where(tmp_label2[:,:,0] != 0 )[0].shape[0] - intersection\n",
    "    \n",
    "    #print(\"uniq labels in resized l2; {}\\n\".format({i:VOC_CLASSES[i] for i in np.unique(tmp_label2)}))\n",
    "\n",
    "    ##plt.figure(figsize=(10, 7))\n",
    "    ##plt.imshow(transparent_overlays(color_im(label1, colors), color_im(tmp_label2, colors), 0.45))\n",
    "    ##plt.show()\n",
    "    \n",
    "    #IU = intersectionAndUnion(label1, tmp_label2, len(VOC_CLASSES))\n",
    "    #print(f\"IntersectionAndUnion is {IU}\\n\\n\")\n",
    "    #return intersectionOverUnion(IU)\n",
    "    return intersection/union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### For each class look at all combinations of 2 (pairs) and calculate the iou of their labels (excluding the BG class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = \"\"\n",
    "for i, c in enumerate(VOC_CLASSES):\n",
    "    if c != 'background':\n",
    "        #print(c)\n",
    "        sub_data = df[df[c]==1]\n",
    "        #print(f\"numbers of image: {len(sub_data)} \\n\\n\")\n",
    "        count = 0\n",
    "        for pair in itertools.combinations(sub_data['fpath_img'],2):\n",
    "            row1 = df[df['fpath_img']==pair[0]]\n",
    "            row2 = df[df['fpath_img']==pair[1]]\n",
    "            imgs = [row1['fpath_img'].values[0],row2['fpath_img'].values[0]]\n",
    "            segms = [row1['fpath_segm'].values[0],row2['fpath_segm'].values[0]]\n",
    "\n",
    "            w, h =  row1['width'].values[0], row1['height'].values[0]\n",
    "\n",
    "            iou = vis_pair(imgs[0], imgs[1], segms[0], segms[1])\n",
    "            #if iou > 0.5 :\n",
    "            new_line = {}\n",
    "            new_line[\"fpath_img\"], new_line[\"fpath_segm\"], new_line[\"width\"], new_line[\"height\"], new_line['iou'] = \\\n",
    "                    imgs, segms, int(w), int(h), iou\n",
    "            #print(new_line)\n",
    "            output += json.dumps(new_line) + \"\\n\"\n",
    "\n",
    "with open('../data/VOC_pairs_iou.odgt', 'w') as fp:\n",
    "    fp.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.read_json('../data/VOC_pairs_iou.odgt', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6d8809a490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pairs['iou'].hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This analysis shows that in a dataset like VOC, the iou of the pairs of images representing the same class is actually very small. It would be interesting to do the same this for city scapes, plant dataset, ... It is likely that we get a different histogram for datasets that have evolving characteristics or evolving content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath_img</th>\n",
       "      <th>fpath_segm</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>0.246318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>0.159835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>0.062326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>[/data/sara/semantic-segmentation-pytorch/data...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>0.123133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           fpath_img  \\\n",
       "0  [/data/sara/semantic-segmentation-pytorch/data...   \n",
       "1  [/data/sara/semantic-segmentation-pytorch/data...   \n",
       "2  [/data/sara/semantic-segmentation-pytorch/data...   \n",
       "3  [/data/sara/semantic-segmentation-pytorch/data...   \n",
       "4  [/data/sara/semantic-segmentation-pytorch/data...   \n",
       "\n",
       "                                          fpath_segm  width  height       iou  \n",
       "0  [/data/sara/semantic-segmentation-pytorch/data...    281     500  0.246318  \n",
       "1  [/data/sara/semantic-segmentation-pytorch/data...    281     500  0.159835  \n",
       "2  [/data/sara/semantic-segmentation-pytorch/data...    281     500  0.062326  \n",
       "3  [/data/sara/semantic-segmentation-pytorch/data...    281     500  0.000000  \n",
       "4  [/data/sara/semantic-segmentation-pytorch/data...    281     500  0.123133  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
