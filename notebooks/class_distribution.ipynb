{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "needed-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "VOC_CLASSES = [\n",
    "    \"background\",\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"diningtable\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"potted plant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tv/monitor\",\n",
    "]\n",
    "\n",
    "\n",
    "VOC_COLORMAP = [\n",
    "    [0, 0, 0],\n",
    "    [128, 0, 0],\n",
    "    [0, 128, 0],\n",
    "    [128, 128, 0],\n",
    "    [0, 0, 128],\n",
    "    [128, 0, 128],\n",
    "    [0, 128, 128],\n",
    "    [128, 128, 128],\n",
    "    [64, 0, 0],\n",
    "    [192, 0, 0],\n",
    "    [64, 128, 0],\n",
    "    [192, 128, 0],\n",
    "    [64, 0, 128],\n",
    "    [192, 0, 128],\n",
    "    [64, 128, 128],\n",
    "    [192, 128, 128],\n",
    "    [0, 64, 0],\n",
    "    [128, 64, 0],\n",
    "    [0, 192, 0],\n",
    "    [128, 192, 0],\n",
    "    [0, 64, 128],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "thousand-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classes list from image path        \n",
    "def get_classes_names(path, class_names):\n",
    "    gray = cv2.imread(path, 0)\n",
    "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret_list = []\n",
    "    for i in np.unique(gray): ret_list.append(class_names[i])\n",
    "    return ret_list\n",
    "\n",
    "\n",
    "def get_class_dist_df(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    dict_data = [json.loads(val) for val in data]\n",
    "    df = pd.DataFrame(dict_data)\n",
    "    \n",
    "    # dict of classes. 1:contain class, 0:NO class\n",
    "    classes = {val:[] for val in VOC_CLASSES}\n",
    "    image_ids = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        label_path = row['fpath_segm']\n",
    "        img_id = label_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "        image_ids.append(img_id)\n",
    "        tmp_classes = get_classes_names(label_path, VOC_CLASSES)\n",
    "\n",
    "        for k, v in classes.items():\n",
    "            if k in tmp_classes:\n",
    "                classes[k].append(1)\n",
    "            else:\n",
    "                classes[k].append(0)\n",
    "\n",
    "    df['id'] = image_ids\n",
    "\n",
    "    for k, v in classes.items():\n",
    "        df[k] = classes[k]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "terminal-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../supervised_odgts/VOCtrain_1000.odgt'\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "dict_data = [json.loads(val) for val in data]\n",
    "df = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "improved-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of classes. 1:contain class, 0:NO class\n",
    "classes = {val:[] for val in VOC_CLASSES}\n",
    "image_ids = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    label_path = row['fpath_segm']\n",
    "    img_id = label_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    image_ids.append(img_id)\n",
    "    tmp_classes = get_classes_names(label_path, VOC_CLASSES)\n",
    "    \n",
    "    for k, v in classes.items():\n",
    "        if k in tmp_classes:\n",
    "            classes[k].append(1)\n",
    "        else:\n",
    "            classes[k].append(0)\n",
    "            \n",
    "df['id'] = image_ids\n",
    "\n",
    "for k, v in classes.items():\n",
    "    df[k] = classes[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "remarkable-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath_img</th>\n",
       "      <th>fpath_segm</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>id</th>\n",
       "      <th>background</th>\n",
       "      <th>aeroplane</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>bird</th>\n",
       "      <th>boat</th>\n",
       "      <th>...</th>\n",
       "      <th>diningtable</th>\n",
       "      <th>dog</th>\n",
       "      <th>horse</th>\n",
       "      <th>motorbike</th>\n",
       "      <th>person</th>\n",
       "      <th>potted plant</th>\n",
       "      <th>sheep</th>\n",
       "      <th>sofa</th>\n",
       "      <th>train</th>\n",
       "      <th>tv/monitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>281</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000063</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000068</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           fpath_img  \\\n",
       "0  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "1  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "2  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "3  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "4  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "\n",
       "                                          fpath_segm  width  height  \\\n",
       "0  /data/sara/semantic-segmentation-pytorch/datas...    281     500   \n",
       "1  /data/sara/semantic-segmentation-pytorch/datas...    375     500   \n",
       "2  /data/sara/semantic-segmentation-pytorch/datas...    375     500   \n",
       "3  /data/sara/semantic-segmentation-pytorch/datas...    375     500   \n",
       "4  /data/sara/semantic-segmentation-pytorch/datas...    375     500   \n",
       "\n",
       "            id  background  aeroplane  bicycle  bird  boat  ...  diningtable  \\\n",
       "0  2007_000032           1          1        0     0     0  ...            0   \n",
       "1  2007_000039           1          0        0     0     0  ...            0   \n",
       "2  2007_000063           1          0        0     0     0  ...            0   \n",
       "3  2007_000068           1          0        0     1     0  ...            0   \n",
       "4  2007_000121           1          0        0     0     0  ...            0   \n",
       "\n",
       "   dog  horse  motorbike  person  potted plant  sheep  sofa  train  tv/monitor  \n",
       "0    0      0          0       1             0      0     0      0           0  \n",
       "1    0      0          0       0             0      0     0      0           1  \n",
       "2    1      0          0       0             0      0     0      0           0  \n",
       "3    0      0          0       0             0      0     0      0           0  \n",
       "4    0      0          0       0             0      0     0      0           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "processed-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/voc_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "tropical-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath_img</th>\n",
       "      <th>fpath_segm</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>id</th>\n",
       "      <th>background</th>\n",
       "      <th>aeroplane</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>bird</th>\n",
       "      <th>boat</th>\n",
       "      <th>...</th>\n",
       "      <th>diningtable</th>\n",
       "      <th>dog</th>\n",
       "      <th>horse</th>\n",
       "      <th>motorbike</th>\n",
       "      <th>person</th>\n",
       "      <th>potted plant</th>\n",
       "      <th>sheep</th>\n",
       "      <th>sofa</th>\n",
       "      <th>train</th>\n",
       "      <th>tv/monitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>366</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>335</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>2007_000123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>/data/sara/semantic-segmentation-pytorch/datas...</td>\n",
       "      <td>500</td>\n",
       "      <td>334</td>\n",
       "      <td>2007_000129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           fpath_img  \\\n",
       "0  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "1  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "2  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "3  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "4  /data/sara/semantic-segmentation-pytorch/datas...   \n",
       "\n",
       "                                          fpath_segm  width  height  \\\n",
       "0  /data/sara/semantic-segmentation-pytorch/datas...    366     500   \n",
       "1  /data/sara/semantic-segmentation-pytorch/datas...    335     500   \n",
       "2  /data/sara/semantic-segmentation-pytorch/datas...    333     500   \n",
       "3  /data/sara/semantic-segmentation-pytorch/datas...    375     500   \n",
       "4  /data/sara/semantic-segmentation-pytorch/datas...    500     334   \n",
       "\n",
       "            id  background  aeroplane  bicycle  bird  boat  ...  diningtable  \\\n",
       "0  2007_000033           1          1        0     0     0  ...            0   \n",
       "1  2007_000042           1          0        0     0     0  ...            0   \n",
       "2  2007_000061           1          0        0     0     1  ...            0   \n",
       "3  2007_000123           1          0        0     0     0  ...            0   \n",
       "4  2007_000129           1          0        1     0     0  ...            0   \n",
       "\n",
       "   dog  horse  motorbike  person  potted plant  sheep  sofa  train  tv/monitor  \n",
       "0    0      0          0       0             0      0     0      0           0  \n",
       "1    0      0          0       0             0      0     0      1           0  \n",
       "2    0      0          0       0             0      0     0      0           0  \n",
       "3    0      0          0       0             0      0     0      1           0  \n",
       "4    0      0          0       1             0      0     0      0           0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = get_class_dist_df('../val_odgts/VOCval_1000.odgt')\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "rational-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_df)\n",
    "# val_df.to_csv('../data/voc_val_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "every-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fpath_img       /data/sara/semantic-segmentation-pytorch/datas...\n",
       "fpath_segm      /data/sara/semantic-segmentation-pytorch/datas...\n",
       "width                                                      559469\n",
       "height                                                     680928\n",
       "id              2007_0000332007_0000422007_0000612007_00012320...\n",
       "background                                                   1449\n",
       "aeroplane                                                      90\n",
       "bicycle                                                        79\n",
       "bird                                                          103\n",
       "boat                                                           72\n",
       "bottle                                                         96\n",
       "bus                                                            74\n",
       "car                                                           127\n",
       "cat                                                           119\n",
       "chair                                                         123\n",
       "cow                                                            71\n",
       "diningtable                                                    75\n",
       "dog                                                           128\n",
       "horse                                                          79\n",
       "motorbike                                                      76\n",
       "person                                                        446\n",
       "potted plant                                                   85\n",
       "sheep                                                          57\n",
       "sofa                                                           90\n",
       "train                                                          84\n",
       "tv/monitor                                                     74\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "disturbed-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fpath_img       /data/sara/semantic-segmentation-pytorch/datas...\n",
       "fpath_segm      /data/sara/semantic-segmentation-pytorch/datas...\n",
       "width                                                      561083\n",
       "height                                                     693801\n",
       "id              2007_0000322007_0000392007_0000632007_00006820...\n",
       "background                                                   1464\n",
       "aeroplane                                                      88\n",
       "bicycle                                                        65\n",
       "bird                                                          105\n",
       "boat                                                           78\n",
       "bottle                                                         87\n",
       "bus                                                            78\n",
       "car                                                           128\n",
       "cat                                                           131\n",
       "chair                                                         148\n",
       "cow                                                            64\n",
       "diningtable                                                    82\n",
       "dog                                                           121\n",
       "horse                                                          68\n",
       "motorbike                                                      81\n",
       "person                                                        442\n",
       "potted plant                                                   82\n",
       "sheep                                                          63\n",
       "sofa                                                           93\n",
       "train                                                          83\n",
       "tv/monitor                                                     83\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-kitty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
