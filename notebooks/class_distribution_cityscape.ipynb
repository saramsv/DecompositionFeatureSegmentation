{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "needed-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "\n",
    "# modified 'license plate' from -1 -> 34 and 19\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , 34 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "CLASS_MAP = {val.id:val.name for val in labels}\n",
    "COLOR_MAP = {val.id:val.color for val in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classes list from image path        \n",
    "def get_classes_names(path, class_names):\n",
    "    gray = cv2.imread(path, 0)\n",
    "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret_list = []\n",
    "    for i in np.unique(gray): ret_list.append(class_names[i])\n",
    "    return ret_list\n",
    "\n",
    "\n",
    "def get_class_dist_df(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    dict_data = [json.loads(val) for val in data]\n",
    "    df = pd.DataFrame(dict_data)\n",
    "    \n",
    "    # dict of classes. 1:contain class, 0:NO class\n",
    "    classes = {val:[] for val in VOC_CLASSES}\n",
    "    image_ids = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        label_path = row['fpath_segm']\n",
    "        img_id = label_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "        image_ids.append(img_id)\n",
    "        tmp_classes = get_classes_names(label_path, VOC_CLASSES)\n",
    "\n",
    "        for k, v in classes.items():\n",
    "            if k in tmp_classes:\n",
    "                classes[k].append(1)\n",
    "            else:\n",
    "                classes[k].append(0)\n",
    "\n",
    "    df['id'] = image_ids\n",
    "\n",
    "    for k, v in classes.items():\n",
    "        df[k] = classes[k]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_image(path, colors):\n",
    "    img = cv2.imread(path)\n",
    "    for i, v in colors.items():\n",
    "        img[:,:,0][np.where(img[:,:,0] == i)] = v[0]\n",
    "        img[:,:,1][np.where(img[:,:,1] == i)] = v[1]\n",
    "        img[:,:,2][np.where(img[:,:,2] == i)] = v[2]\n",
    "    return img\n",
    "\n",
    "def seg_infor(seg_path, class_names):\n",
    "    seg = cv2.imread(seg_path, 0)\n",
    "    h = seg.shape[0]\n",
    "    w = seg.shape[1]\n",
    "    # seg_classes = [class_names[i] for i in np.unique(seg)]\n",
    "    seg_classes = []\n",
    "    for i in np.unique(seg):\n",
    "        # in case, I just want eval classes\n",
    "        try: \n",
    "            seg_classes.append(class_names[i])\n",
    "        except:\n",
    "            pass\n",
    "    return seg_classes, w, h\n",
    "\n",
    "# assume img are in \"leftImg8bit/\"\n",
    "def path_segToimg(seg_path):\n",
    "    img_path = seg_path.replace('gtFine', 'leftImg8bit', 1)\n",
    "    img_path = img_path.replace('gtFine_labelIds', 'leftImg8bit')\n",
    "    return img_path\n",
    "\n",
    "# assume seg are in \"gtFine/\"\n",
    "def path_imgToseg(img_path):\n",
    "    seg_path = img_path.replace(\"leftImg8bit\", \"gtFine\", 1)\n",
    "    seg_path = seg_path.replace(\"leftImg8bit\", \"gtFine_labelIds\")\n",
    "    return seg_path\n",
    "\n",
    "'''\n",
    "- file_path\n",
    "    - city a \n",
    "        - img1\n",
    "        - img2\n",
    "    - city b\n",
    "        - img1\n",
    "        - img2\n",
    "    ...\n",
    "''' \n",
    "\n",
    "def get_all_imgs(file_path):\n",
    "    # file_path = \"/usb/datasets/cityscapes_dataset/leftImg8bit/train/\"\n",
    "    cities_train = os.listdir(file_path)\n",
    "    all_imgs = []\n",
    "    for c in cities_train:\n",
    "        imgs = [\"{}{}/{}\".format(file_path, c, i) for i in os.listdir(\"{}{}\".format(file_path, c))]\n",
    "        all_imgs.extend(imgs)\n",
    "    return all_imgs\n",
    "\n",
    "def df_gen(train_imgs_path, CLASS_MAP):\n",
    "    train_segs_path = []\n",
    "    for img in train_imgs_path:\n",
    "        seg_path = path_imgToseg(img)\n",
    "        train_segs_path.append(seg_path)\n",
    "\n",
    "    cities = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    class_list_dict = {v:[] for k, v in CLASS_MAP.items()}\n",
    "\n",
    "    for seg in tqdm(train_segs_path):\n",
    "        seg_classes, w, h = seg_infor(seg, CLASS_MAP)\n",
    "        city = seg.split('/')[-2]\n",
    "\n",
    "        cities.append(city)\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "\n",
    "        for k, v in CLASS_MAP.items():\n",
    "            if v in seg_classes:\n",
    "                class_list_dict[v].append(1)\n",
    "            else:\n",
    "                class_list_dict[v].append(0)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df['image'] = train_imgs_path\n",
    "    df['segmentation'] = train_segs_path\n",
    "    df['city'] = cities\n",
    "    df['width'] = widths\n",
    "    df['height'] = heights\n",
    "\n",
    "    for k, v in class_list_dict.items():\n",
    "        df[k] = class_list_dict[k]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/train/\")\n",
    "df = df_gen(imgs_path, CLASS_MAP)\n",
    "print(\"train: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/train.csv\")\n",
    "\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/val/\")\n",
    "df = df_gen(imgs_path, CLASS_MAP)\n",
    "print(\"val: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/val.csv\")\n",
    "\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/test/\")\n",
    "df = df_gen(imgs_path, CLASS_MAP)\n",
    "print(\"test: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/test.csv\")\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-extra",
   "metadata": {},
   "source": [
    "## EVAL Cityscape Classes Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_CLASS_MAP = {}\n",
    "EVAL_COLOR_MAP = {}\n",
    "\n",
    "for val in labels:\n",
    "    if not val.ignoreInEval:\n",
    "        EVAL_CLASS_MAP[val.trainId] = val.name\n",
    "        EVAL_COLOR_MAP[val.trainId] = val.color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/train/\")\n",
    "df = df_gen(imgs_path, EVAL_CLASS_MAP)\n",
    "print(\"train: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/eval_train.csv\")\n",
    "\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/val/\")\n",
    "df = df_gen(imgs_path, EVAL_CLASS_MAP)\n",
    "print(\"val: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/eval_val.csv\")\n",
    "\n",
    "imgs_path = get_all_imgs(\"/usb/datasets/cityscapes_dataset/leftImg8bit/test/\")\n",
    "df = df_gen(imgs_path, EVAL_CLASS_MAP)\n",
    "print(\"test: {}\".format(len(df)))\n",
    "df.to_csv(\"../data/cityscape_csv/eval_test.csv\")\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-timothy",
   "metadata": {},
   "source": [
    "# Calculating IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chicken-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pair(img1, img2, label1, label2):\n",
    "    img1 = cv2.imread(img1)\n",
    "    img2 = cv2.imread(img2)\n",
    "    label1 = cv2.imread(label1)\n",
    "    label2 = cv2.imread(label2)\n",
    "    \n",
    "    tmp_label2 = cv2.resize(label2, (int(label1.shape[1]), int(label1.shape[0])))\n",
    "    \n",
    "    label1[np.where(label1 == 0)] = 255 # to exclude the bg from intersection\n",
    "    \n",
    "    intersection = np.where(label1[:,:,0] == tmp_label2[:,:,0])[0].shape[0]\n",
    "    union = np.where(label1[:,:,0] != 255 )[0].shape[0] + np.where(tmp_label2[:,:,0] != 0 )[0].shape[0] - intersection\n",
    "\n",
    "    return intersection/union\n",
    "\n",
    "\n",
    "def class_pair_iou(df, CLASS_LIST):\n",
    "    output = \"\"\n",
    "    for i, c in enumerate(CLASS_LIST):\n",
    "        if c != 'unlabeled':\n",
    "            sub_data = df[df[c]==1]\n",
    "            count = 0\n",
    "            pbar = tqdm(total=sum(1 for ignore in itertools.combinations(sub_data['image'], 2)))\n",
    "            for pair in itertools.combinations(sub_data['image'], 2):\n",
    "                pbar.set_description(\"{}\".format(c))\n",
    "                pbar.update(1)\n",
    "                row1 = df[df['image']==pair[0]]\n",
    "                row2 = df[df['image']==pair[1]]\n",
    "                imgs = [row1['image'].values[0],row2['image'].values[0]]\n",
    "                segms = [row1['segmentation'].values[0], row2['segmentation'].values[0]]\n",
    "                w, h =  row1['width'].values[0], row1['height'].values[0]\n",
    "                iou = vis_pair(imgs[0], imgs[1], segms[0], segms[1])\n",
    "                new_line = {}\n",
    "                new_line[\"fpath_img\"], new_line[\"fpath_segm\"], new_line[\"width\"], new_line[\"height\"], new_line['iou'] = \\\n",
    "                        imgs, segms, int(w), int(h), iou\n",
    "                output += json.dumps(new_line) + \"\\n\"\n",
    "                \n",
    "                # test\n",
    "                break\n",
    "            pbar.close()\n",
    "    return output\n",
    "\n",
    "def save_odgt(file_to_save, output_path, overwrite=False):\n",
    "    if os.path.exists(file_to_save) and not overwrite:\n",
    "        print(\"File exists!\")\n",
    "        return\n",
    "    elif os.path.exists(file_to_save) and overwrite:\n",
    "        print(\"Overwrite file!\")\n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(file_to_save)\n",
    "        \n",
    "def plot_hist_from_odgt(file_path, greater_than=0.5):\n",
    "    df_pairs = pd.read_json(file_path, lines=True)\n",
    "    df_pairs[df_pairs['iou'] > greater_than]['iou'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cityscape_csv/train.csv\")\n",
    "CLASS_LIST = list(EVAL_CLASS_MAP.values())\n",
    "\n",
    "output = class_pair_iou(df, CLASS_LIST)\n",
    "save_odgt(output, '../data/cityscape_csv/test.odgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occasional-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist_from_odgt('../data/cityscape_csv/eval_train_all_iou.odgt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-berkeley",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/usb/datasets/cityscapes_dataset/leftImg8bit/train/stuttgart/stuttgart_000110_000019_leftImg8bit.png'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "\n",
    "img_path = '/usb/datasets/cityscapes_dataset/leftImg8bit/train/stuttgart/stuttgart_000111_000019_leftImg8bit.png'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_seg = color_image(path_imgToseg(img_path), COLOR_MAP)\n",
    "plt.figure(figsize=(13, 13))\n",
    "plt.imshow(colored_seg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-charge",
   "metadata": {},
   "source": [
    "## DataFrames Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cityscape_csv/eval_train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-capability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
